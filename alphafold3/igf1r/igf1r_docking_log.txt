INFO:    gocryptfs not found, will not be able to use gocryptfs
I0623 17:39:53.604518 23279892980864 xla_bridge.py:895] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0623 17:39:53.628318 23279892980864 xla_bridge.py:895] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory

Running AlphaFold 3. Please note that standard AlphaFold 3 model parameters are
only available under terms of use provided at
https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md.
If you do not agree to these terms and are using AlphaFold 3 derived model
parameters, cancel execution of AlphaFold 3 inference with CTRL-C, and do not
use the model parameters.

Found local devices: [CudaDevice(id=0)], using device 0: cuda:0
Building model from scratch...
Checking that model parameters can be loaded...

Running fold job igf1r...
Output will be written in /root/af_output/igf1r_20250623_173958 since /root/af_output/igf1r is non-empty.
Skipping data pipeline...
Writing model input JSON to /root/af_output/igf1r_20250623_173958/igf1r_data.json
Predicting 3D structure for igf1r with 10 seed(s)...
Featurising data with 10 seed(s)...
Featurising data with seed 1.
I0623 17:40:05.436282 23279892980864 pipeline.py:166] processing igf1r, random_seed=1
I0623 17:40:05.466183 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:05.466359 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:08.409315 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:09.950654 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 1 took 4.59 seconds.
Featurising data with seed 2.
I0623 17:40:10.029200 23279892980864 pipeline.py:166] processing igf1r, random_seed=2
I0623 17:40:10.047739 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:10.047827 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:12.892751 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:14.453829 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 2 took 4.50 seconds.
Featurising data with seed 3.
I0623 17:40:14.524950 23279892980864 pipeline.py:166] processing igf1r, random_seed=3
I0623 17:40:14.544454 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:14.544548 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:17.505555 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:19.098943 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 3 took 4.65 seconds.
Featurising data with seed 4.
I0623 17:40:19.170784 23279892980864 pipeline.py:166] processing igf1r, random_seed=4
I0623 17:40:19.189481 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:19.189593 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:22.094959 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:23.649615 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 4 took 4.55 seconds.
Featurising data with seed 5.
I0623 17:40:23.719719 23279892980864 pipeline.py:166] processing igf1r, random_seed=5
I0623 17:40:23.738431 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:23.738514 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:26.647645 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:28.216770 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 5 took 4.57 seconds.
Featurising data with seed 6.
I0623 17:40:28.286544 23279892980864 pipeline.py:166] processing igf1r, random_seed=6
I0623 17:40:28.305375 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:28.305488 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:31.184733 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:32.748282 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 6 took 4.53 seconds.
Featurising data with seed 7.
I0623 17:40:32.817138 23279892980864 pipeline.py:166] processing igf1r, random_seed=7
I0623 17:40:32.835307 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:32.835392 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:35.743379 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:37.309058 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 7 took 4.56 seconds.
Featurising data with seed 8.
I0623 17:40:37.380621 23279892980864 pipeline.py:166] processing igf1r, random_seed=8
I0623 17:40:37.399324 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:37.399415 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:40.315506 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:41.893437 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 8 took 4.58 seconds.
Featurising data with seed 9.
I0623 17:40:41.964313 23279892980864 pipeline.py:166] processing igf1r, random_seed=9
I0623 17:40:41.983854 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:41.983957 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:44.913006 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:46.468574 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 9 took 4.57 seconds.
Featurising data with seed 10.
I0623 17:40:46.536545 23279892980864 pipeline.py:166] processing igf1r, random_seed=10
I0623 17:40:46.554889 23279892980864 pipeline.py:259] Calculating bucket size for input with 286 tokens.
I0623 17:40:46.554964 23279892980864 pipeline.py:265] Got bucket size 512 for input with 286 tokens, resulting in 226 padded tokens.
I0623 17:40:49.523942 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
I0623 17:40:51.081566 23279892980864 features.py:1520] Using SMILES for: LIG_B - Cc1cc(-n2ccnc2)cc2nc(-c3c(NCc4ccccn4)cc[nH]c3=O)[nH]c12
Featurising data with seed 10 took 4.62 seconds.
Featurising data with 10 seed(s) took 52.75 seconds.
Running model inference and extracting output structure samples with 10 seed(s)...
Running model inference with seed 1...
Running model inference with seed 1 took 123.21 seconds.
Extracting inference results with seed 1...
Extracting 5 inference samples with seed 1 took 0.29 seconds.
Running model inference with seed 2...
Running model inference with seed 2 took 93.14 seconds.
Extracting inference results with seed 2...
Extracting 5 inference samples with seed 2 took 0.27 seconds.
Running model inference with seed 3...
Running model inference with seed 3 took 93.18 seconds.
Extracting inference results with seed 3...
Extracting 5 inference samples with seed 3 took 0.27 seconds.
Running model inference with seed 4...
Running model inference with seed 4 took 93.16 seconds.
Extracting inference results with seed 4...
Extracting 5 inference samples with seed 4 took 0.27 seconds.
Running model inference with seed 5...
Running model inference with seed 5 took 93.16 seconds.
Extracting inference results with seed 5...
Extracting 5 inference samples with seed 5 took 0.46 seconds.
Running model inference with seed 6...
Running model inference with seed 6 took 93.19 seconds.
Extracting inference results with seed 6...
Extracting 5 inference samples with seed 6 took 0.27 seconds.
Running model inference with seed 7...
Running model inference with seed 7 took 93.15 seconds.
Extracting inference results with seed 7...
Extracting 5 inference samples with seed 7 took 0.27 seconds.
Running model inference with seed 8...
Running model inference with seed 8 took 93.16 seconds.
Extracting inference results with seed 8...
Extracting 5 inference samples with seed 8 took 0.28 seconds.
Running model inference with seed 9...
Running model inference with seed 9 took 93.16 seconds.
Extracting inference results with seed 9...
Extracting 5 inference samples with seed 9 took 0.27 seconds.
Running model inference with seed 10...
Running model inference with seed 10 took 93.15 seconds.
Extracting inference results with seed 10...
Extracting 5 inference samples with seed 10 took 0.27 seconds.
Running model inference and extracting output structures with 10 seed(s) took 964.58 seconds.
Writing outputs with 10 seed(s)...
Fold job igf1r done, output written to /root/af_output/igf1r_20250623_173958

Done running 1 fold jobs.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c4140c04>
Subject: Job 456165: <bash /pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3/../../alphafold3/igf1r/igf1r_docking.sh> in cluster <sci> Done

Job <bash /pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3/../../alphafold3/igf1r/igf1r_docking.sh> was submitted from host <r640c58> by user <ari.ginsparg-umw> in cluster <sci> at Mon Jun 23 16:38:45 2025
Job was executed on host(s) <8*c4140c04>, in queue <gpu>, as user <ari.ginsparg-umw> in cluster <sci> at Mon Jun 23 17:39:44 2025
</home/ari.ginsparg-umw> was used as the home directory.
</pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3> was used as the working directory.
Started at Mon Jun 23 17:39:44 2025
Terminated at Mon Jun 23 17:57:07 2025
Results reported at Mon Jun 23 17:57:07 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
bash /pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3/../../alphafold3/igf1r/igf1r_docking.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1024.70 sec.
    Max Memory :                                 5095 MB
    Average Memory :                             4897.33 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               11289.00 MB
    Max Swap :                                   -
    Max Processes :                              7
    Max Threads :                                343
    Run time :                                   1043 sec.
    Turnaround time :                            4702 sec.

The output (if any) is above this job summary.

