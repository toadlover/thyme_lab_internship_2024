INFO:    gocryptfs not found, will not be able to use gocryptfs
I0623 17:13:53.543839 23203311191168 xla_bridge.py:895] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0623 17:13:53.568341 23203311191168 xla_bridge.py:895] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory

Running AlphaFold 3. Please note that standard AlphaFold 3 model parameters are
only available under terms of use provided at
https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md.
If you do not agree to these terms and are using AlphaFold 3 derived model
parameters, cancel execution of AlphaFold 3 inference with CTRL-C, and do not
use the model parameters.

Found local devices: [CudaDevice(id=0)], using device 0: cuda:0
Building model from scratch...
Checking that model parameters can be loaded...

Running fold job fabp4...
Output will be written in /root/af_output/fabp4_20250623_171358 since /root/af_output/fabp4 is non-empty.
Skipping data pipeline...
Writing model input JSON to /root/af_output/fabp4_20250623_171358/fabp4_data.json
Predicting 3D structure for fabp4 with 10 seed(s)...
Featurising data with 10 seed(s)...
Featurising data with seed 1.
I0623 17:14:05.548808 23203311191168 pipeline.py:166] processing fabp4, random_seed=1
I0623 17:14:05.573700 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:05.573870 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:06.699068 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:07.561048 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 1 took 2.10 seconds.
Featurising data with seed 2.
I0623 17:14:07.651480 23203311191168 pipeline.py:166] processing fabp4, random_seed=2
I0623 17:14:07.663757 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:07.663843 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:08.714232 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:09.621911 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 2 took 2.05 seconds.
Featurising data with seed 3.
I0623 17:14:09.703765 23203311191168 pipeline.py:166] processing fabp4, random_seed=3
I0623 17:14:09.715720 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:09.715799 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:10.805904 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:11.681607 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 3 took 2.06 seconds.
Featurising data with seed 4.
I0623 17:14:11.765767 23203311191168 pipeline.py:166] processing fabp4, random_seed=4
I0623 17:14:11.778009 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:11.778093 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:12.893692 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:13.761011 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 4 took 2.08 seconds.
Featurising data with seed 5.
I0623 17:14:13.844603 23203311191168 pipeline.py:166] processing fabp4, random_seed=5
I0623 17:14:13.856792 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:13.856896 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:14.984028 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:15.831610 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 5 took 2.07 seconds.
Featurising data with seed 6.
I0623 17:14:15.914190 23203311191168 pipeline.py:166] processing fabp4, random_seed=6
I0623 17:14:15.926919 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:15.927014 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:17.047242 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:17.930839 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 6 took 2.10 seconds.
Featurising data with seed 7.
I0623 17:14:18.015459 23203311191168 pipeline.py:166] processing fabp4, random_seed=7
I0623 17:14:18.027847 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:18.027946 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:19.159854 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:19.997206 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 7 took 2.07 seconds.
Featurising data with seed 8.
I0623 17:14:20.080698 23203311191168 pipeline.py:166] processing fabp4, random_seed=8
I0623 17:14:20.093378 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:20.093469 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:21.187142 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:22.031433 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 8 took 2.03 seconds.
Featurising data with seed 9.
I0623 17:14:22.112807 23203311191168 pipeline.py:166] processing fabp4, random_seed=9
I0623 17:14:22.124827 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:22.124902 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:23.235318 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:24.079570 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 9 took 2.05 seconds.
Featurising data with seed 10.
I0623 17:14:24.163226 23203311191168 pipeline.py:166] processing fabp4, random_seed=10
I0623 17:14:24.175365 23203311191168 pipeline.py:259] Calculating bucket size for input with 167 tokens.
I0623 17:14:24.175450 23203311191168 pipeline.py:265] Got bucket size 256 for input with 167 tokens, resulting in 89 padded tokens.
I0623 17:14:25.297112 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
I0623 17:14:26.164375 23203311191168 features.py:1520] Using SMILES for: LIG_B - CCc1c(-c2ccccc2)c(-c2ccccc2)nn1-c1ccccc1-c1cccc(OCC(=O)[O-])c1
Featurising data with seed 10 took 2.08 seconds.
Featurising data with 10 seed(s) took 28.14 seconds.
Running model inference and extracting output structure samples with 10 seed(s)...
Running model inference with seed 1...
Running model inference with seed 1 took 54.95 seconds.
Extracting inference results with seed 1...
Extracting 5 inference samples with seed 1 took 0.18 seconds.
Running model inference with seed 2...
Running model inference with seed 2 took 27.34 seconds.
Extracting inference results with seed 2...
Extracting 5 inference samples with seed 2 took 0.14 seconds.
Running model inference with seed 3...
Running model inference with seed 3 took 27.35 seconds.
Extracting inference results with seed 3...
Extracting 5 inference samples with seed 3 took 0.14 seconds.
Running model inference with seed 4...
Running model inference with seed 4 took 27.36 seconds.
Extracting inference results with seed 4...
Extracting 5 inference samples with seed 4 took 0.14 seconds.
Running model inference with seed 5...
Running model inference with seed 5 took 27.37 seconds.
Extracting inference results with seed 5...
Extracting 5 inference samples with seed 5 took 0.14 seconds.
Running model inference with seed 6...
Running model inference with seed 6 took 27.37 seconds.
Extracting inference results with seed 6...
Extracting 5 inference samples with seed 6 took 0.14 seconds.
Running model inference with seed 7...
Running model inference with seed 7 took 27.37 seconds.
Extracting inference results with seed 7...
Extracting 5 inference samples with seed 7 took 0.14 seconds.
Running model inference with seed 8...
Running model inference with seed 8 took 27.37 seconds.
Extracting inference results with seed 8...
Extracting 5 inference samples with seed 8 took 0.14 seconds.
Running model inference with seed 9...
Running model inference with seed 9 took 27.37 seconds.
Extracting inference results with seed 9...
Extracting 5 inference samples with seed 9 took 0.14 seconds.
Running model inference with seed 10...
Running model inference with seed 10 took 27.37 seconds.
Extracting inference results with seed 10...
Extracting 5 inference samples with seed 10 took 0.14 seconds.
Running model inference and extracting output structures with 10 seed(s) took 302.63 seconds.
Writing outputs with 10 seed(s)...
Fold job fabp4 done, output written to /root/af_output/fabp4_20250623_171358

Done running 1 fold jobs.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c4140c04>
Subject: Job 456147: <bash /pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3/../../alphafold3/fabp4/fabp4_docking.sh> in cluster <sci> Done

Job <bash /pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3/../../alphafold3/fabp4/fabp4_docking.sh> was submitted from host <r640c58> by user <ari.ginsparg-umw> in cluster <sci> at Mon Jun 23 16:38:37 2025
Job was executed on host(s) <8*c4140c04>, in queue <gpu>, as user <ari.ginsparg-umw> in cluster <sci> at Mon Jun 23 17:13:43 2025
</home/ari.ginsparg-umw> was used as the home directory.
</pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3> was used as the working directory.
Started at Mon Jun 23 17:13:43 2025
Terminated at Mon Jun 23 17:19:38 2025
Results reported at Mon Jun 23 17:19:38 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
bash /pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3/../../alphafold3/fabp4/fabp4_docking.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   350.91 sec.
    Max Memory :                                 4783 MB
    Average Memory :                             4336.17 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               11601.00 MB
    Max Swap :                                   -
    Max Processes :                              7
    Max Threads :                                343
    Run time :                                   355 sec.
    Turnaround time :                            2461 sec.

The output (if any) is above this job summary.

