INFO:    gocryptfs not found, will not be able to use gocryptfs
I0623 16:44:47.841701 22455010403456 xla_bridge.py:895] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
I0623 16:44:47.865242 22455010403456 xla_bridge.py:895] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory

Running AlphaFold 3. Please note that standard AlphaFold 3 model parameters are
only available under terms of use provided at
https://github.com/google-deepmind/alphafold3/blob/main/WEIGHTS_TERMS_OF_USE.md.
If you do not agree to these terms and are using AlphaFold 3 derived model
parameters, cancel execution of AlphaFold 3 inference with CTRL-C, and do not
use the model parameters.

Found local devices: [CudaDevice(id=0)], using device 0: cuda:0
Building model from scratch...
Checking that model parameters can be loaded...

Running fold job andr...
Output will be written in /root/af_output/andr_20250623_164452 since /root/af_output/andr is non-empty.
Skipping data pipeline...
Writing model input JSON to /root/af_output/andr_20250623_164452/andr_data.json
Predicting 3D structure for andr with 10 seed(s)...
Featurising data with 10 seed(s)...
Featurising data with seed 1.
I0623 16:44:59.706364 22455010403456 pipeline.py:166] processing andr, random_seed=1
I0623 16:44:59.736450 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:44:59.736644 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:01.440370 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:02.869783 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 1 took 3.27 seconds.
Featurising data with seed 2.
I0623 16:45:02.975610 22455010403456 pipeline.py:166] processing andr, random_seed=2
I0623 16:45:02.992311 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:45:02.992398 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:04.696250 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:06.118550 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 2 took 3.24 seconds.
Featurising data with seed 3.
I0623 16:45:06.219073 22455010403456 pipeline.py:166] processing andr, random_seed=3
I0623 16:45:06.235007 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:45:06.235086 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:07.978133 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:09.390481 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 3 took 3.27 seconds.
Featurising data with seed 4.
I0623 16:45:09.487486 22455010403456 pipeline.py:166] processing andr, random_seed=4
I0623 16:45:09.503942 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:45:09.504022 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:11.244079 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:12.645940 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 4 took 3.25 seconds.
Featurising data with seed 5.
I0623 16:45:12.741597 22455010403456 pipeline.py:166] processing andr, random_seed=5
I0623 16:45:12.757761 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:45:12.757835 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:14.440962 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:15.866455 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 5 took 3.22 seconds.
Featurising data with seed 6.
I0623 16:45:15.964025 22455010403456 pipeline.py:166] processing andr, random_seed=6
I0623 16:45:15.980926 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:45:15.981018 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:17.707529 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:19.096068 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 6 took 3.23 seconds.
Featurising data with seed 7.
I0623 16:45:19.194558 22455010403456 pipeline.py:166] processing andr, random_seed=7
I0623 16:45:19.210887 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:45:19.210966 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:20.904692 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:22.284572 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 7 took 3.19 seconds.
Featurising data with seed 8.
I0623 16:45:22.380354 22455010403456 pipeline.py:166] processing andr, random_seed=8
I0623 16:45:22.396767 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:45:22.396848 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:24.064747 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:25.465636 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 8 took 3.18 seconds.
Featurising data with seed 9.
I0623 16:45:25.563102 22455010403456 pipeline.py:166] processing andr, random_seed=9
I0623 16:45:25.579318 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:45:25.579393 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:27.272768 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:28.672994 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 9 took 3.21 seconds.
Featurising data with seed 10.
I0623 16:45:28.770104 22455010403456 pipeline.py:166] processing andr, random_seed=10
I0623 16:45:28.786393 22455010403456 pipeline.py:259] Calculating bucket size for input with 250 tokens.
I0623 16:45:28.786487 22455010403456 pipeline.py:265] Got bucket size 256 for input with 250 tokens, resulting in 6 padded tokens.
I0623 16:45:30.458393 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
I0623 16:45:31.861402 22455010403456 features.py:1520] Using SMILES for: LIG_B - C[C@]12CC[C@H]3[C@@H](CCC4=C[C@H](O)CC[C@@]43C)[C@@H]1CC[C@@H]2O
Featurising data with seed 10 took 3.19 seconds.
Featurising data with 10 seed(s) took 39.10 seconds.
Running model inference and extracting output structure samples with 10 seed(s)...
Running model inference with seed 1...
Running model inference with seed 1 took 54.83 seconds.
Extracting inference results with seed 1...
Extracting 5 inference samples with seed 1 took 0.26 seconds.
Running model inference with seed 2...
Running model inference with seed 2 took 27.64 seconds.
Extracting inference results with seed 2...
Extracting 5 inference samples with seed 2 took 0.24 seconds.
Running model inference with seed 3...
Running model inference with seed 3 took 27.66 seconds.
Extracting inference results with seed 3...
Extracting 5 inference samples with seed 3 took 0.24 seconds.
Running model inference with seed 4...
Running model inference with seed 4 took 27.67 seconds.
Extracting inference results with seed 4...
Extracting 5 inference samples with seed 4 took 0.42 seconds.
Running model inference with seed 5...
Running model inference with seed 5 took 27.68 seconds.
Extracting inference results with seed 5...
Extracting 5 inference samples with seed 5 took 0.24 seconds.
Running model inference with seed 6...
Running model inference with seed 6 took 27.66 seconds.
Extracting inference results with seed 6...
Extracting 5 inference samples with seed 6 took 0.24 seconds.
Running model inference with seed 7...
Running model inference with seed 7 took 27.68 seconds.
Extracting inference results with seed 7...
Extracting 5 inference samples with seed 7 took 0.23 seconds.
Running model inference with seed 8...
Running model inference with seed 8 took 27.68 seconds.
Extracting inference results with seed 8...
Extracting 5 inference samples with seed 8 took 0.23 seconds.
Running model inference with seed 9...
Running model inference with seed 9 took 27.69 seconds.
Extracting inference results with seed 9...
Extracting 5 inference samples with seed 9 took 0.23 seconds.
Running model inference with seed 10...
Running model inference with seed 10 took 27.68 seconds.
Extracting inference results with seed 10...
Extracting 5 inference samples with seed 10 took 0.24 seconds.
Running model inference and extracting output structures with 10 seed(s) took 306.42 seconds.
Writing outputs with 10 seed(s)...
Fold job andr done, output written to /root/af_output/andr_20250623_164452

Done running 1 fold jobs.

------------------------------------------------------------
Sender: LSF System <lsfadmin@c4140c05>
Subject: Job 456126: <bash /pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3/../../alphafold3/andr/andr_docking.sh> in cluster <sci> Done

Job <bash /pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3/../../alphafold3/andr/andr_docking.sh> was submitted from host <r640c58> by user <ari.ginsparg-umw> in cluster <sci> at Mon Jun 23 16:38:27 2025
Job was executed on host(s) <8*c4140c05>, in queue <gpu>, as user <ari.ginsparg-umw> in cluster <sci> at Mon Jun 23 16:44:42 2025
</home/ari.ginsparg-umw> was used as the home directory.
</pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3> was used as the working directory.
Started at Mon Jun 23 16:44:42 2025
Terminated at Mon Jun 23 16:50:46 2025
Results reported at Mon Jun 23 16:50:46 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
bash /pi/summer.thyme-umw/2024_intern_lab_space/thyme_lab_internship_2024/scripts/alphafold3/../../alphafold3/andr/andr_docking.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   367.15 sec.
    Max Memory :                                 4810 MB
    Average Memory :                             4439.04 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               11574.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                342
    Run time :                                   363 sec.
    Turnaround time :                            739 sec.

The output (if any) is above this job summary.

